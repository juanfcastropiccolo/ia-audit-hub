# Ejemplo de configuración para LiteLlm
model_list:
  # Configuración para Anthropic Claude
  - model_name: claude-3-opus
    litellm_params:
      model: anthropic/claude-3-opus
      api_key: sk-ant-YOUR-API-KEY

  - model_name: claude-3-sonnet
    litellm_params:
      model: anthropic/claude-3-sonnet
      api_key: sk-ant-YOUR-API-KEY

  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku
      api_key: sk-ant-YOUR-API-KEY

  # Configuración para OpenAI
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: sk-YOUR-API-KEY

  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: sk-YOUR-API-KEY

  # Configuración para Gemini (Google)
  - model_name: gemini-pro
    litellm_params:
      model: gemini/gemini-1.5-pro
      api_key: YOUR-GOOGLE-API-KEY

  - model_name: gemini-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: YOUR-GOOGLE-API-KEY

# Enrutamiento por defecto para peticiones genéricas
router_settings:
  routing_strategy: simple-shuffle
  model_group_alias:
    - name: claude
      models:
        - claude-3-opus
        - claude-3-sonnet
        - claude-3-haiku

    - name: gpt
      models:
        - gpt-4
        - gpt-3.5-turbo
    
    - name: gemini
      models:
        - gemini-pro
        - gemini-flash

# Configuración de LLM por defecto
litellm_settings:
  drop_params: true
  set_verbose: true
  telemetry: false
  max_tokens: 2000 